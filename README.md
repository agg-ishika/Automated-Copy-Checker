# Automated-Copy-Checker

# Introduction
The major goal of the suggested system is to evaluate the answer sheets more accurately and  with less effort to fully automate the process of assessing the response. We used previous research to come up with a solution where the evaluations can be done automatically and with precision and with the least error.
We assessed the problems of evaluators and reduced them to almost 90% saving them a huge amount of time.

# Installations
1. Visual Studio Code (Editor)
2. Python 

# Python Libraries
1. BeautifulSoup4
2. Requests
3. html5lib
4. Pandas 

# Data Set
We collect data set from various students through circulating a google form. All the students have submit their answers to some questions, so that we get 
sample input as typed answers or paragraph by student's side. We compare this answer from answer we get after web scraping from google.

# Working of the Project
The overall process is divided into five sub-processes.The result we get is on a scale of 0 to 9 then convert them intelligently to percentages.
The major part of our system is that we not only focus on the score that is generated by the system, but also provided a human evaluated scores in order to 
make a comparison between the two obtained result for greater accuracy check and consistency.  The comparison is made using ML Algorithm "Cosine Similarity Index"
Process I Summarization of actual answers of Students
Process II Web Scraping process and getting extracted text from URL
Process III Summarization of Extracted text
Process IV Comparison between two Answers obtained (Called as Ground Truths)
Process V Allocation of marks using Cosine Similarity

# Results and Discussion
**1. Division of classes in ranges and allocating Marks**
The allocation of marks after calculating the cosine similarity is done by making classes based on the ranges on a scale of 0 to 9. These classes tell us the
category of the answer, such as Good, Very Good or Excellent. This helps to make the process of allocation of marks more smooth and organised.

**2. Calculation of Cosine similarity**
The proposed system uses cosine similarity to normalize the length of documents. It is calculated between two tokenized texts and an approximate score is 
given based on the comparison between the student's answer and the actual answer. The cosine similarity is found in the range [-1,1], which when multiplied 
by 10 generates the marks scored by the student.

**3. Comparison b/w Human Evaluation and Proposed System**
This step plays an important role in checking the accuracy of the proposed system. we first show the result obtained by the algorithm developed using the 
tools and technology. After that, we also evaluated the student's responses manually with the help of teachers in order to check the consistency of the result.

